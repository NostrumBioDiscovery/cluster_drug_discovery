

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>From python API &mdash; cluster_drug_discovery 1.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="From Command Line" href="../command_line_tutorial/index.html" />
    <link rel="prev" title="Getting Started" href="../index.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> cluster_drug_discovery
          

          
          </a>

          
            
            
              <div class="version">
                1.0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation/index.html">Installation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Getting Started</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">From python API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#analyze-dataset">Analyze Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#silhouette">Silhouette</a></li>
<li class="toctree-l4"><a class="reference internal" href="#carlinski">Carlinski</a></li>
<li class="toctree-l4"><a class="reference internal" href="#david-bouldin">David-Bouldin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#analysis-conclusion">Analysis Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#clustering-algorithms">Clustering Algorithms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#kmeans">Kmeans</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dbscan">DBSCAN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hierarchichal">Hierarchichal</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../command_line_tutorial/index.html">From Command Line</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../changelog/index.html">ChangeLog</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">cluster_drug_discovery</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Getting Started</a> &raquo;</li>
        
      <li>From python API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorial/api_tutorial/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="from-python-api">
<h1>From python API<a class="headerlink" href="#from-python-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="analyze-dataset">
<h2>Analyze Dataset<a class="headerlink" href="#analyze-dataset" title="Permalink to this headline">¶</a></h2>
<p>Tha analysis is based on:</p>
<ul class="simple">
<li>Silhouette index:  The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). Therefore, as high as possible the better.</li>
<li>Calinski-Harabasz index: The score is defined as ratio between the within-cluster dispersion and the between-cluster dispersion.</li>
<li>David-Bouldin index: The score refers to a model with better separation between the clusters.</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">mixture</span>
<span class="kn">import</span> <span class="nn">cluster_drug_discovery.methods.kmeans</span> <span class="k">as</span> <span class="nn">ks</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">KmeansAlg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">nclust</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cluster</span><span class="o">.</span><span class="n">analysis_run</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="silhouette">
<h3>Silhouette<a class="headerlink" href="#silhouette" title="Permalink to this headline">¶</a></h3>
<p>As seen in the pictures belowe as high the silhoutte coeficient
is the better the clustering. As the silhoutte coefficient give us
a sense of how separate each point is from the other clusters.</p>
<p>Therefore, when we move from 3 to 4 clusters the silhouette index
of the first and second cluster clearly drops as they are next to each
other in the feature space while with nclusters=3 all clusters were very
separated.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/silhouette_2.png"><img alt="../../_images/silhouette_2.png" src="../../_images/silhouette_2.png" style="width: 900.0px; height: 350.0px;" /></a>
</div>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/silhouette_3.png"><img alt="../../_images/silhouette_3.png" src="../../_images/silhouette_3.png" style="width: 900.0px; height: 350.0px;" /></a>
</div>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/silhouette_4.png"><img alt="../../_images/silhouette_4.png" src="../../_images/silhouette_4.png" style="width: 900.0px; height: 350.0px;" /></a>
</div>
</div>
<div class="section" id="carlinski">
<h3>Carlinski<a class="headerlink" href="#carlinski" title="Permalink to this headline">¶</a></h3>
<p>In terms of the  Calinski-Harabasz index the score is higher when clusters are dense and well separated,
which relates to a standard concept of a cluster. The score is fast to compute.
Whereas, The Calinski-Harabasz index is generally higher for convex clusters than other concepts of clusters,
such as density based clusters like those obtained through DBSCAN.</p>
<p>As seen in the plot belowe as Calinski index is based only on density it gives a better
score for ncluster=4 than ncluster=3 as the clusters are smaller and therefore more dense.
However, that does not mean that the result is better. In conclusion, this index give us usufull
information about the cluster density but must be use with other indexes like the silhoutte.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/calinski_score.png"><img alt="../../_images/calinski_score.png" src="../../_images/calinski_score.png" style="width: 512.0px; height: 384.0px;" /></a>
</div>
</div>
<div class="section" id="david-bouldin">
<h3>David-Bouldin<a class="headerlink" href="#david-bouldin" title="Permalink to this headline">¶</a></h3>
<p>The David-Bouldin score refers to a model with better separation between the clusters since algorithms that produce clusters with low intra-cluster distances (high intra-cluster similarity) and high inter-cluster distances (low inter-cluster similarity) will have a low Davies–Bouldin index, the clustering algorithm that produces a collection of clusters with the smallest Davies–Bouldin index is considered the best algorithm based on this criterion.</p>
<p>As seen in the plot below we can clearly differenciate that moving from nclust=2 to nclust=3 the intra-cluster
distance gets better. However, from nclust=3 and nclust=4 the intra-cluster distance remains the same and the
values does no change that much.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/davidbouldin_score.png"><img alt="../../_images/davidbouldin_score.png" src="../../_images/davidbouldin_score.png" style="width: 512.0px; height: 384.0px;" /></a>
</div>
</div>
<div class="section" id="analysis-conclusion">
<h3>Analysis Conclusion<a class="headerlink" href="#analysis-conclusion" title="Permalink to this headline">¶</a></h3>
<p>All indexes give useful information, then the most efficient anlysis
to set the clustering parameters would be to put the three of them
together with some visualization tool (dimensionallity reduction).</p>
</div>
</div>
<div class="section" id="clustering-algorithms">
<h2>Clustering Algorithms<a class="headerlink" href="#clustering-algorithms" title="Permalink to this headline">¶</a></h2>
<div class="section" id="kmeans">
<h3>Kmeans<a class="headerlink" href="#kmeans" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul>
<li><p class="first">Advantages :</p>
<blockquote>
<div><ul class="simple">
<li>If variables are huge, then  K-Means most of the times computationally faster than hierarchical clustering, if we keep k smalls.</li>
<li>K-Means produce tighter clusters than hierarchical clustering, especially if the clusters are globular.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Disadvantages :</p>
<blockquote>
<div><ul class="simple">
<li>Difficult to predict K-Value.</li>
<li>With global cluster, it didn’t work well.</li>
<li>Different initial partitions can result in different final clusters.</li>
<li>It does not work well with different size and density clusters</li>
</ul>
</div></blockquote>
</li>
</ul>
<p>Learn more: <a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cluster_drug_discovery.methods</span> <span class="k">import</span> <span class="n">kmeans</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">KmeansAlg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">nclust</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">i_dataset</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
<p>Kmeans works for globular clusters:</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/kmeans_work.png"><img alt="../../_images/kmeans_work.png" src="../../_images/kmeans_work.png" style="width: 512.0px; height: 384.0px;" /></a>
</div>
<p>But not for density-different o converx clusters:</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/kmeans_no_work.png"><img alt="../../_images/kmeans_no_work.png" src="../../_images/kmeans_no_work.png" style="width: 512.0px; height: 384.0px;" /></a>
</div>
</div>
<div class="section" id="dbscan">
<h3>DBSCAN<a class="headerlink" href="#dbscan" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul>
<li><p class="first">Advantages of DBSCAN:</p>
<blockquote>
<div><ul class="simple">
<li>Is great at separating clusters of high density versus clusters of low density within a given dataset.</li>
<li>Is great with handling outliers within the dataset.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Disadvantages of DBSCAN:</p>
<blockquote>
<div><ul class="simple">
<li>Does not work well when dealing with clusters of varying densities. While DBSCAN is great at separating high density clusters from low density clusters, DBSCAN struggles with clusters of similar density.</li>
<li>Struggles with high dimensionality data. I know, this entire article I have stated how DBSCAN is great at contorting the data into different dimensions and shapes. However, DBSCAN can only go so far, if given data with too many dimensions, DBSCAN suffers</li>
</ul>
</div></blockquote>
</li>
</ul>
<blockquote>
<div><p>Learn more: <a class="reference external" href="https://en.wikipedia.org/wiki/DBSCAN">https://en.wikipedia.org/wiki/DBSCAN</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cluster_drug_discovery.methods</span> <span class="k">import</span> <span class="n">dbscan</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">dbscan</span><span class="o">.</span><span class="n">DbscanAlg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">nclust</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">i_dataset</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
<p>DBSCAN works for non globular clusters but suffers with high dimensionallity</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/dbscan.png"><img alt="../../_images/dbscan.png" src="../../_images/dbscan.png" style="width: 512.0px; height: 384.0px;" /></a>
</div>
</div>
<div class="section" id="hierarchichal">
<h3>Hierarchichal<a class="headerlink" href="#hierarchichal" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul>
<li><p class="first">Advantages</p>
<blockquote>
<div><ul class="simple">
<li>No apriori information about the number of clusters required.</li>
<li>Easy to implement and gives best result in some cases.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Disadvantages</p>
<blockquote>
<div><ul class="simple">
<li>Algorithm can never undo what was done previously.</li>
<li></li>
<li>Time complexity of at least O(n2 log n) is required, where ‘n’ is the number of data points.</li>
<li></li>
<li>Based on the type of distance matrix chosen for merging different algorithms can suffer with outliers &amp; complexity</li>
</ul>
</div></blockquote>
</li>
</ul>
<blockquote>
<div><p>Learn more: <a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">https://en.wikipedia.org/wiki/Hierarchical_clustering</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cluster_drug_discovery.methods</span> <span class="k">import</span> <span class="n">agglomerative</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">agglomerative</span><span class="o">.</span><span class="n">AgglomerativeAlg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">nclust</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">i_dataset</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
<p>Agglomerative Clustering works for globular data but not convex datasets</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/agglomerative.png"><img alt="../../_images/agglomerative.png" src="../../_images/agglomerative.png" style="width: 512.0px; height: 384.0px;" /></a>
</div>
<blockquote>
<div><blockquote>
<div><ul class="simple">
<li>No apriori information about the number of clusters required.</li>
<li>Easy to implement and gives best result in some cases.</li>
</ul>
</div></blockquote>
<ul>
<li><p class="first">Disadvantages</p>
<blockquote>
<div><ul class="simple">
<li>Algorithm can never undo what was done previously.</li>
<li></li>
<li>Time complexity of at least O(n2 log n) is required, where ‘n’ is the number of data points.</li>
<li></li>
<li>Based on the type of distance matrix chosen for merging different algorithms can suffer with outliers &amp; complexity</li>
</ul>
</div></blockquote>
</li>
</ul>
<blockquote>
<div><p>Learn more: <a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">https://en.wikipedia.org/wiki/Hierarchical_clustering</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cluster_drug_discovery.methods</span> <span class="k">import</span> <span class="n">agglomerative</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">agglomerative</span><span class="o">.</span><span class="n">AgglomerativeAlg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">nclust</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">i_dataset</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
<p>Agglomerative Clustering works for globular data but not convex datasets</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/agglomerative.png"><img alt="../../_images/agglomerative.png" src="../../_images/agglomerative.png" style="width: 512.0px; height: 384.0px;" /></a>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../command_line_tutorial/index.html" class="btn btn-neutral float-right" title="From Command Line" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral" title="Getting Started" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Daniel Soler Viladrich

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>